---
permalink: technical-reports/datalake-analytics.html 
sidebar: sidebar 
keywords: data lake, on-premises, analytics, storagegrid, object 
summary: このレポートでは、StorageGRIDでのビッグデータ分析について説明します。 
---
= NetApp StorageGRIDとビッグデータ分析
:hardbreaks:
:allow-uri-read: 
:icons: font
:imagesdir: ../media/




== NetApp StorageGRIDのユースケース

NetApp StorageGRIDオブジェクトストレージ解決策は、拡張性、データ可用性、セキュリティ、ハイパフォーマンスを提供します。StorageGRID S3は、あらゆる規模のさまざまな業界の組織で幅広いユースケースに使用されています。典型的なシナリオをいくつか見てみましょう。

*ビッグデータ分析：* StorageGRID S3はデータレイクとしてよく使用されています。企業は、Apache Spark、Splunk Smartstore、Dremioなどのツールを使用して、分析用に大量の構造化データと非構造化データを保存します。

*データ階層化：* NetAppのお客様は、ONTAPのFabricPool機能を使用して、ハイパフォーマンスなローカル階層間でStorageGRIDにデータを自動的に移動します。階層化することで、高価なフラッシュストレージをホットデータ用に解放し、コールドデータを低コストのオブジェクトストレージでいつでも利用できる状態に維持できます。これにより、パフォーマンスとコスト削減が最大化されます。

*データのバックアップとディザスタリカバリ：*企業は、StorageGRID S3を信頼性とコスト効率に優れた解決策として使用して、重要なデータのバックアップと災害時のリカバリを実行できます。

*アプリケーション用のデータストレージ：* StorageGRID S3はアプリケーションのストレージバックエンドとして使用できるため、開発者はファイル、画像、ビデオ、その他の種類のデータを簡単に保存および取得できます。

*コンテンツ配信：* StorageGRID S3を使用すると、静的なWebサイトコンテンツ、メディアファイル、ソフトウェアダウンロードを世界中のユーザに保存して配信できます。StorageGRIDの地理的な配信とグローバルネームスペースを活用して、高速で信頼性の高いコンテンツ配信を実現できます。

*データ階層化：* NetAppのお客様は、ONTAP FabricPool機能を使用して、ハイパフォーマンスなローカル階層間でStorageGRIDにデータを自動的に移動します。階層化することで、高価なフラッシュストレージをホットデータ用に解放し、コールドデータを低コストのオブジェクトストレージからいつでも利用できる状態に保ちます。これにより、パフォーマンスとコスト削減が最大化されます。

*データアーカイブ：* StorageGRIDは、さまざまな種類のストレージを提供し、パブリックな長期低コストストレージオプションへの階層化をサポートします。コンプライアンスや履歴目的で保持する必要があるデータのアーカイブや長期保存に最適な解決策です。

*オブジェクトストレージのユースケース*

image:datalake-analytics/image1.png["StorageGRIDのユースケース図、幅= 396、高さ= 394"]

上記の中で、ビッグデータ分析は最も多くのユースケースの1つであり、その使用量は増加傾向にあります。



== データレイクにStorageGRIDを選ぶ理由

* コラボレーションの強化-業界標準のAPIアクセスによる大規模な共有マルチサイト、マルチテナンシー
* 運用コストの削減-単一の自己回復型自動スケールアウトアーキテクチャによる運用の簡易化
* 拡張性-従来のHadoopやデータウェアハウスソリューションとは異なり、StorageGRID S3オブジェクトストレージはコンピューティングやデータからストレージを切り離し、ビジネスの成長に合わせてストレージニーズを拡張できます。
* 耐久性と信頼性- StorageGRIDは99.999999999%の耐久性を提供し、保存されたデータはデータ損失に対して非常に耐性があります。また、高可用性を提供し、データへの常時アクセスを保証します。
* セキュリティ- StorageGRIDは、暗号化、アクセス制御ポリシー、データライフサイクル管理、オブジェクトロック、S3バケットに格納されたデータを保護するバージョン管理など、さまざまなセキュリティ機能を提供します。


* StorageGRID S3データレイク*

image:datalake-analytics/image2.png["StorageGRIDデータレイクの例、幅= 614、高さ= 345"]



== S3オブジェクトストレージに最も適したデータウェアハウスまたはデータレイク

NetAppは、Hive、Delta Lake、Dremioの3つのデータウェアハウス/レイクハウスエコシステムでStorageGRIDをベンチマークしました。 https://www.dremio.com/wp-content/uploads/2023/02/apache-iceberg-TDG_ER1.pdf?aliId=eyJpIjoieDRUYjFKN2ZMbXhTRnFRWCIsInQiOiJIUUw0djJsWnlJa21iNUsyQURRalNnPT0ifQ%253D%253D["『Apache Iceberg: The Definitive Guide』"] データウェアハウスとデータレイクハウスの簡単な紹介と、これら2つのアーキテクチャの長所と短所が含まれています。

* ベンチマークツール- TPC-DS- https://www.tpc.org/tpcds/[]
* ビッグデータエコシステム
+
** 5台のVMで構成されるクラスタ。各VMに128G RAM、24個のvCPU、システムディスク用SSDストレージが搭載されています。
** Hadoop 3.3.5とHive 3.1.3（1つのネームノード+ 4つのデータノード）
** Delta LakeとSpark 3.2.0（1マスター+ 4ワーカー）およびHadoop 3.3.5
** Dremio v23（マスター1名+エグゼキューター4名）


* オブジェクトストレージ
+
** SG6060を3台+ SG1000ロードバランサを1台搭載した場合、NetApp ^ StorageGRID®^SG^®^11.6
** オブジェクトの保護-コピー×2


* データベースサイズ1000GB
* クエリテストごとに一貫した結果を得るために、3つのエコシステムすべてでキャッシュが無効になりました。


TPC-DSには、クエリベンチマーク用に99の複雑なSQLクエリが付属しています。99個のクエリをすべて完了するまでの合計時間を分単位で測定し、結果を分析するためにS3要求のタイプと数を細かく分析しました。次の表は、全99件のクエリの合計期間を示しています。2番目の表は、各エコシステムがStorageGRIDに送信するS3要求の数とタイプを示しています。

* TPC-DSクエリ結果*

[cols="35%,20%,23%,22%"]
|===
| エコシステム | ハイブ | デルタレイク" | デレミオ 


| ストレージレイヤ | NetApp ^®^ StorageGRID ^®^ | NetApp ^®^ StorageGRID ^®^ | NetApp ^®^ StorageGRID ^®^ 


| ドライブタイプ | HDD | HDD | HDD 


| 表形式 | 寄木細工 | 寄木細工 | 寄木細工^1^ 


| データベースサイズ | 1000 g | 1000 g | 1000 g 


| TPCDS 99クエリ+
合計分数 | 1084^2^ | 55 | 47です 
|===
^1^寄木細工と氷山の両方のテーブル形式をテストしましたが、結果は似ています。

^2^Hiveクエリー番号72を完了できません。

* TPC-DSクエリ- S3要求の内訳*

[cols="24%,24%,27%,25%"]
|===
| S3要求 | ハイブ | デルタレイク" | デレミオ 


| 取得 | 一、一一七、一八四 | 2、074、610 | 四、四一四、二二二七 


| 観察：+
すべての範囲GET | 80%のGET：32MBオブジェクトから2KB～2MB、50~100要求/秒 | 73%の範囲は、32MBオブジェクトから100KB未満、1、000~1400要求/秒 | 90% 1Mバイト範囲は256MBのオブジェクトから取得、2000~2300の要求/秒 


| オブジェクトをリスト表示 | 三一二、〇 五三 | 二四、一五八 | 240 


| 頭部+
（存在しないオブジェクト） | 156、027 | 一二、一 〇 三 | 192年 


| 頭部+
（既存のオブジェクト） | 982、126 | 922、732 | 一、八四五 


| リクエスト総数 | 二、五六七、三九 〇 | 3、033、603 | 4、416、504 
|===
最初のテーブルから、デルタ湖とDremioがHiveよりもはるかに速いことがわかります。2つ目の表から、Hiveが大量のS3リストオブジェクト要求を送信していることがわかります。この要求は、すべてのオブジェクトストレージプラットフォーム（特に多数のオブジェクトを含むバケットを扱う場合）では通常低速です。これにより、全体的なクエリ時間が大幅に長くなります。もう1つの観測点は、Dremioが大量のGET要求を並行して送信することができたことで、Hiveでは毎秒50~100件の要求に対して、毎秒2,000～2300件の要求が送信されたことです。HiveとHadoop S3AのMimic standard filesystemは、S3オブジェクトストレージのHiveの低速化に貢献しています。

Hadoop（HDFSまたはS3オブジェクトストレージ上）をHiveまたはSparkで使用するには、HadoopとHive/Sparkの広範な知識と、各サービスの設定の相互作用に関する知識が必要です。これらの設定の合計数は1000以上です。多くの場合、設定は相互に関連しており、単独で変更することはできません。使用する設定と値の最適な組み合わせを見つけるには、膨大な時間と労力がかかります。

Dremioは、エンドツーエンドのApache Arrowを使用してクエリのパフォーマンスを劇的に向上させるデータレイクエンジンです。Apache Arrowは、効率的なデータ共有と高速分析のために標準化されたカラムナメモリフォーマットを提供します。Arrowは、言語に依存しないアプローチを採用しており、データのシリアライゼーションとデシリアライゼーションの必要性を排除し、複雑なデータプロセスとシステム間のパフォーマンスと相互運用性を向上させるように設計されています。

Dremioの性能は主にDremioクラスター上の計算能力によって駆動される。DremioはS3オブジェクトストレージ接続にHadoopのS3Aコネクタを使用しますが、Hadoopは必須ではなく、Hadoopのfs.s3a設定のほとんどはDremioでは使用されません。これにより、さまざまなHadoop s3a設定の学習とテストに時間を費やすことなく、Dremioのパフォーマンスを簡単に調整できます。

このベンチマーク結果から、S3ベースのワークロード向けに最適化されたビッグデータ分析システムがパフォーマンスの大きな要因であることがわかります。Dremioはクエリの実行を最適化し、メタデータを効率的に利用し、S3データへのシームレスなアクセスを提供するため、S3ストレージを使用する場合にHiveと比較してパフォーマンスが向上します。これを参照してください https://docs.netapp.com/us-en/storagegrid-enable/tools-apps-guides/configure-dremio-storagegrid.html["ページ"] StorageGRIDでDremio S3データソースを設定するには、次の手順を実行します。

StorageGRIDとDremioが連携して最新の効率的なデータレイクインフラを提供する方法や、NetAppがHive + HDFSからDremio + StorageGRIDに移行してビッグデータ分析の効率を劇的に向上させる方法については、以下のリンクをご覧ください。

* https://www.netapp.tv/details/31426?mcid=02148179640195118863901007338453703701["NetApp StorageGRIDでビッグデータのパフォーマンスを向上"]
* https://www.netapp.com/media/80932-SB-4236-StorageGRID-Dremio.pdf["StorageGRIDとDremioによる、パワフルで効率性に優れた最新のデータレイクインフラ"]
* https://youtu.be/Y57Gyj4De2I?si=nwVG5ohCj93TggKS["NetAppが製品分析でカスタマーエクスペリエンスを再定義する方法"]

